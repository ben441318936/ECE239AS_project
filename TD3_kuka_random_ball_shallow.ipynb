{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines import TD3\n",
    "from stable_baselines.td3.policies import LnMlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.ddpg.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "from stable_baselines.common.callbacks import CheckpointCallback, EvalCallback\n",
    "from stable_baselines.bench import Monitor\n",
    "\n",
    "from modules import CustomTD3Policy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from modules import KukaBulletGymRandomBall\n",
    "\n",
    "import os\n",
    "\n",
    "# Reloading any code written in external .py files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging and saving directories\n",
    "parent = \"./TD3_kuka_random_ball_shallow/\"\n",
    "checkpoint_path = parent + \"checkpoints/\"\n",
    "best_model_path = parent + \"best_model/\"\n",
    "eval_log_path = parent + \"eval_logs/\"\n",
    "monitor_log_path = parent + \"monitor_logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make environment with monitor wrapper\n",
    "env = KukaBulletGymRandomBall.KukaBulletGym(render=False)\n",
    "wrapped_env = Monitor(env, monitor_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make callbacks\n",
    "checkpoint_callback = CheckpointCallback(save_freq=50000, \n",
    "                                         save_path=checkpoint_path,\n",
    "                                         name_prefix=\"model\")\n",
    "eval_callback = EvalCallback(env,\n",
    "                             best_model_save_path=best_model_path, \n",
    "                             log_path=eval_log_path,\n",
    "                             eval_freq=1000, \n",
    "                             deterministic=True, \n",
    "                             render=False,\n",
    "                             verbose=0,\n",
    "                             n_eval_episodes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "model = TD3.load(\"./TD3_kuka_fixed_ball_shallow/checkpoints/end_manual\")\n",
    "model.set_env(wrapped_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\stable_bl\\lib\\site-packages\\stable_baselines\\common\\callbacks.py:277: UserWarning: Training and eval env are not of the same type<Monitor<KukaBulletGym instance>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000001E5421CD988>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 12        |\n",
      "| episodes                | 5000      |\n",
      "| eplenmean               | 4.01      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 12        |\n",
      "| n_updates               | 21900     |\n",
      "| qf1_loss                | 172.74847 |\n",
      "| qf2_loss                | 166.4186  |\n",
      "| time_elapsed            | 1874      |\n",
      "| total timesteps         | 22062     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 9.94      |\n",
      "| episodes                | 10000     |\n",
      "| eplenmean               | 4.2       |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 9.9       |\n",
      "| n_updates               | 41200     |\n",
      "| qf1_loss                | 205.93178 |\n",
      "| qf2_loss                | 200.89215 |\n",
      "| time_elapsed            | 3580      |\n",
      "| total timesteps         | 41321     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 13.9      |\n",
      "| episodes                | 15000     |\n",
      "| eplenmean               | 3.73      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 13.9      |\n",
      "| n_updates               | 61000     |\n",
      "| qf1_loss                | 247.74126 |\n",
      "| qf2_loss                | 232.26544 |\n",
      "| time_elapsed            | 5305      |\n",
      "| total timesteps         | 61136     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 20.1      |\n",
      "| episodes                | 20000     |\n",
      "| eplenmean               | 4.99      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 20.1      |\n",
      "| n_updates               | 81300     |\n",
      "| qf1_loss                | 223.07033 |\n",
      "| qf2_loss                | 220.59027 |\n",
      "| time_elapsed            | 7045      |\n",
      "| total timesteps         | 81451     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 11.1      |\n",
      "| episodes                | 25000     |\n",
      "| eplenmean               | 5.05      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 11.1      |\n",
      "| n_updates               | 105600    |\n",
      "| qf1_loss                | 217.68806 |\n",
      "| qf2_loss                | 213.33875 |\n",
      "| time_elapsed            | 8939      |\n",
      "| total timesteps         | 105739    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 6.01      |\n",
      "| episodes                | 30000     |\n",
      "| eplenmean               | 3.49      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 6         |\n",
      "| n_updates               | 128900    |\n",
      "| qf1_loss                | 174.89235 |\n",
      "| qf2_loss                | 173.02492 |\n",
      "| time_elapsed            | 10826     |\n",
      "| total timesteps         | 129009    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 13.8      |\n",
      "| episodes                | 35000     |\n",
      "| eplenmean               | 3.98      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 13.8      |\n",
      "| n_updates               | 146900    |\n",
      "| qf1_loss                | 202.09361 |\n",
      "| qf2_loss                | 200.68288 |\n",
      "| time_elapsed            | 12480     |\n",
      "| total timesteps         | 147091    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 11.6      |\n",
      "| episodes                | 40000     |\n",
      "| eplenmean               | 3.22      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 11.6      |\n",
      "| n_updates               | 164400    |\n",
      "| qf1_loss                | 205.27092 |\n",
      "| qf2_loss                | 203.9641  |\n",
      "| time_elapsed            | 14095     |\n",
      "| total timesteps         | 164563    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 13        |\n",
      "| episodes                | 45000     |\n",
      "| eplenmean               | 3.34      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 13        |\n",
      "| n_updates               | 181500    |\n",
      "| qf1_loss                | 229.4387  |\n",
      "| qf2_loss                | 228.25725 |\n",
      "| time_elapsed            | 15709     |\n",
      "| total timesteps         | 181616    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 10.5      |\n",
      "| episodes                | 50000     |\n",
      "| eplenmean               | 3.22      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 10.5      |\n",
      "| n_updates               | 198400    |\n",
      "| qf1_loss                | 234.96173 |\n",
      "| qf2_loss                | 244.50703 |\n",
      "| time_elapsed            | 17342     |\n",
      "| total timesteps         | 198544    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 9.43      |\n",
      "| episodes                | 55000     |\n",
      "| eplenmean               | 3.34      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 9.4       |\n",
      "| n_updates               | 215000    |\n",
      "| qf1_loss                | 223.3047  |\n",
      "| qf2_loss                | 222.99142 |\n",
      "| time_elapsed            | 18953     |\n",
      "| total timesteps         | 215129    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 14.1      |\n",
      "| episodes                | 60000     |\n",
      "| eplenmean               | 3.43      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 14.1      |\n",
      "| n_updates               | 231100    |\n",
      "| qf1_loss                | 230.36368 |\n",
      "| qf2_loss                | 223.87047 |\n",
      "| time_elapsed            | 20535     |\n",
      "| total timesteps         | 231281    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.4      |\n",
      "| episodes                | 65000     |\n",
      "| eplenmean               | 3.32      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 17.4      |\n",
      "| n_updates               | 247000    |\n",
      "| qf1_loss                | 254.14133 |\n",
      "| qf2_loss                | 246.58076 |\n",
      "| time_elapsed            | 22111     |\n",
      "| total timesteps         | 247190    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 11.8      |\n",
      "| episodes                | 70000     |\n",
      "| eplenmean               | 3.53      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 11.8      |\n",
      "| n_updates               | 263100    |\n",
      "| qf1_loss                | 263.48306 |\n",
      "| qf2_loss                | 256.38644 |\n",
      "| time_elapsed            | 23687     |\n",
      "| total timesteps         | 263256    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 12.7      |\n",
      "| episodes                | 75000     |\n",
      "| eplenmean               | 3.16      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 12.7      |\n",
      "| n_updates               | 280300    |\n",
      "| qf1_loss                | 257.77863 |\n",
      "| qf2_loss                | 255.34229 |\n",
      "| time_elapsed            | 25304     |\n",
      "| total timesteps         | 280459    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 12.9      |\n",
      "| episodes                | 80000     |\n",
      "| eplenmean               | 3.33      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 12.9      |\n",
      "| n_updates               | 297100    |\n",
      "| qf1_loss                | 268.65015 |\n",
      "| qf2_loss                | 258.14554 |\n",
      "| time_elapsed            | 27222     |\n",
      "| total timesteps         | 297218    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 9.7       |\n",
      "| episodes                | 85000     |\n",
      "| eplenmean               | 3.5       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 9.7       |\n",
      "| n_updates               | 313800    |\n",
      "| qf1_loss                | 270.48755 |\n",
      "| qf2_loss                | 267.77673 |\n",
      "| time_elapsed            | 28797     |\n",
      "| total timesteps         | 313943    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 15.1      |\n",
      "| episodes                | 90000     |\n",
      "| eplenmean               | 3.37      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 15.1      |\n",
      "| n_updates               | 330400    |\n",
      "| qf1_loss                | 278.6076  |\n",
      "| qf2_loss                | 281.06357 |\n",
      "| time_elapsed            | 30394     |\n",
      "| total timesteps         | 330567    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 12.3      |\n",
      "| episodes                | 95000     |\n",
      "| eplenmean               | 3.42      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 12.3      |\n",
      "| n_updates               | 347100    |\n",
      "| qf1_loss                | 279.10718 |\n",
      "| qf2_loss                | 275.7561  |\n",
      "| time_elapsed            | 32005     |\n",
      "| total timesteps         | 347204    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 21.2      |\n",
      "| episodes                | 100000    |\n",
      "| eplenmean               | 2.97      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 21.2      |\n",
      "| n_updates               | 363600    |\n",
      "| qf1_loss                | 268.2152  |\n",
      "| qf2_loss                | 273.74756 |\n",
      "| time_elapsed            | 33596     |\n",
      "| total timesteps         | 363725    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 26        |\n",
      "| episodes                | 105000    |\n",
      "| eplenmean               | 3.3       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 26        |\n",
      "| n_updates               | 380000    |\n",
      "| qf1_loss                | 249.32835 |\n",
      "| qf2_loss                | 251.38348 |\n",
      "| time_elapsed            | 35201     |\n",
      "| total timesteps         | 380129    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.3      |\n",
      "| episodes                | 110000    |\n",
      "| eplenmean               | 3.39      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.3      |\n",
      "| n_updates               | 396500    |\n",
      "| qf1_loss                | 279.73663 |\n",
      "| qf2_loss                | 283.449   |\n",
      "| time_elapsed            | 36786     |\n",
      "| total timesteps         | 396670    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 24.9      |\n",
      "| episodes                | 115000    |\n",
      "| eplenmean               | 3.37      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 24.9      |\n",
      "| n_updates               | 412700    |\n",
      "| qf1_loss                | 284.1107  |\n",
      "| qf2_loss                | 291.01508 |\n",
      "| time_elapsed            | 38366     |\n",
      "| total timesteps         | 412883    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 13.2      |\n",
      "| episodes                | 120000    |\n",
      "| eplenmean               | 3.16      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 13.2      |\n",
      "| n_updates               | 427700    |\n",
      "| qf1_loss                | 279.13382 |\n",
      "| qf2_loss                | 283.23572 |\n",
      "| time_elapsed            | 39907     |\n",
      "| total timesteps         | 427819    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 9.39      |\n",
      "| episodes                | 125000    |\n",
      "| eplenmean               | 2.95      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 9.4       |\n",
      "| n_updates               | 443200    |\n",
      "| qf1_loss                | 285.77716 |\n",
      "| qf2_loss                | 282.15594 |\n",
      "| time_elapsed            | 41476     |\n",
      "| total timesteps         | 443337    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 15.4      |\n",
      "| episodes                | 130000    |\n",
      "| eplenmean               | 3.38      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 15.4      |\n",
      "| n_updates               | 459400    |\n",
      "| qf1_loss                | 282.82043 |\n",
      "| qf2_loss                | 279.60397 |\n",
      "| time_elapsed            | 42960     |\n",
      "| total timesteps         | 459505    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 21.9      |\n",
      "| episodes                | 135000    |\n",
      "| eplenmean               | 3.69      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 21.9      |\n",
      "| n_updates               | 475900    |\n",
      "| qf1_loss                | 304.48053 |\n",
      "| qf2_loss                | 304.48254 |\n",
      "| time_elapsed            | 44394     |\n",
      "| total timesteps         | 476063    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 20.7      |\n",
      "| episodes                | 140000    |\n",
      "| eplenmean               | 3.41      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 20.7      |\n",
      "| n_updates               | 492600    |\n",
      "| qf1_loss                | 326.35495 |\n",
      "| qf2_loss                | 318.7441  |\n",
      "| time_elapsed            | 45982     |\n",
      "| total timesteps         | 492769    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 16.5      |\n",
      "| episodes                | 145000    |\n",
      "| eplenmean               | 3.45      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 16.5      |\n",
      "| n_updates               | 509400    |\n",
      "| qf1_loss                | 304.89697 |\n",
      "| qf2_loss                | 303.43524 |\n",
      "| time_elapsed            | 47587     |\n",
      "| total timesteps         | 509518    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 18.8      |\n",
      "| episodes                | 150000    |\n",
      "| eplenmean               | 3.33      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 18.8      |\n",
      "| n_updates               | 526300    |\n",
      "| qf1_loss                | 281.09256 |\n",
      "| qf2_loss                | 276.14386 |\n",
      "| time_elapsed            | 49197     |\n",
      "| total timesteps         | 526414    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 18.4      |\n",
      "| episodes                | 155000    |\n",
      "| eplenmean               | 3.65      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 18.4      |\n",
      "| n_updates               | 543400    |\n",
      "| qf1_loss                | 312.9952  |\n",
      "| qf2_loss                | 311.60043 |\n",
      "| time_elapsed            | 50805     |\n",
      "| total timesteps         | 543513    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 11.2      |\n",
      "| episodes                | 160000    |\n",
      "| eplenmean               | 3.42      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 11.2      |\n",
      "| n_updates               | 561100    |\n",
      "| qf1_loss                | 314.92108 |\n",
      "| qf2_loss                | 306.7272  |\n",
      "| time_elapsed            | 52446     |\n",
      "| total timesteps         | 561246    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 11.3      |\n",
      "| episodes                | 165000    |\n",
      "| eplenmean               | 3.12      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 11.3      |\n",
      "| n_updates               | 579200    |\n",
      "| qf1_loss                | 330.63824 |\n",
      "| qf2_loss                | 331.78406 |\n",
      "| time_elapsed            | 54106     |\n",
      "| total timesteps         | 579390    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 15.3      |\n",
      "| episodes                | 170000    |\n",
      "| eplenmean               | 3.59      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 15.3      |\n",
      "| n_updates               | 597600    |\n",
      "| qf1_loss                | 336.75616 |\n",
      "| qf2_loss                | 326.9092  |\n",
      "| time_elapsed            | 55767     |\n",
      "| total timesteps         | 597773    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 37.2      |\n",
      "| episodes                | 175000    |\n",
      "| eplenmean               | 3.95      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 37.2      |\n",
      "| n_updates               | 616400    |\n",
      "| qf1_loss                | 320.46878 |\n",
      "| qf2_loss                | 317.67563 |\n",
      "| time_elapsed            | 57463     |\n",
      "| total timesteps         | 616583    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 18.4      |\n",
      "| episodes                | 180000    |\n",
      "| eplenmean               | 3.32      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 18.4      |\n",
      "| n_updates               | 634500    |\n",
      "| qf1_loss                | 352.2644  |\n",
      "| qf2_loss                | 347.58817 |\n",
      "| time_elapsed            | 59120     |\n",
      "| total timesteps         | 634675    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 22.1      |\n",
      "| episodes                | 185000    |\n",
      "| eplenmean               | 3.73      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 22.1      |\n",
      "| n_updates               | 652200    |\n",
      "| qf1_loss                | 333.12985 |\n",
      "| qf2_loss                | 330.64624 |\n",
      "| time_elapsed            | 60766     |\n",
      "| total timesteps         | 652335    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 19.8     |\n",
      "| episodes                | 190000   |\n",
      "| eplenmean               | 3.64     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 19.8     |\n",
      "| n_updates               | 671400   |\n",
      "| qf1_loss                | 332.4844 |\n",
      "| qf2_loss                | 336.7563 |\n",
      "| time_elapsed            | 62465    |\n",
      "| total timesteps         | 671548   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 19.8      |\n",
      "| episodes                | 195000    |\n",
      "| eplenmean               | 3.63      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 19.8      |\n",
      "| n_updates               | 689900    |\n",
      "| qf1_loss                | 344.853   |\n",
      "| qf2_loss                | 342.49646 |\n",
      "| time_elapsed            | 64148     |\n",
      "| total timesteps         | 690011    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 15.5      |\n",
      "| episodes                | 200000    |\n",
      "| eplenmean               | 3.21      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 15.5      |\n",
      "| n_updates               | 707600    |\n",
      "| qf1_loss                | 376.72168 |\n",
      "| qf2_loss                | 372.594   |\n",
      "| time_elapsed            | 65773     |\n",
      "| total timesteps         | 707787    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 16.4      |\n",
      "| episodes                | 205000    |\n",
      "| eplenmean               | 3.48      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 16.4      |\n",
      "| n_updates               | 724900    |\n",
      "| qf1_loss                | 363.24808 |\n",
      "| qf2_loss                | 361.45856 |\n",
      "| time_elapsed            | 67417     |\n",
      "| total timesteps         | 725033    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 20.6      |\n",
      "| episodes                | 210000    |\n",
      "| eplenmean               | 3.64      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 20.6      |\n",
      "| n_updates               | 743300    |\n",
      "| qf1_loss                | 353.17358 |\n",
      "| qf2_loss                | 353.92328 |\n",
      "| time_elapsed            | 69074     |\n",
      "| total timesteps         | 743412    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 25.4      |\n",
      "| episodes                | 215000    |\n",
      "| eplenmean               | 3.58      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 25.4      |\n",
      "| n_updates               | 760600    |\n",
      "| qf1_loss                | 360.17136 |\n",
      "| qf2_loss                | 356.77695 |\n",
      "| time_elapsed            | 70696     |\n",
      "| total timesteps         | 760763    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.4      |\n",
      "| episodes                | 220000    |\n",
      "| eplenmean               | 3.5       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.4      |\n",
      "| n_updates               | 778400    |\n",
      "| qf1_loss                | 345.0476  |\n",
      "| qf2_loss                | 341.84302 |\n",
      "| time_elapsed            | 72352     |\n",
      "| total timesteps         | 778503    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 28.5      |\n",
      "| episodes                | 225000    |\n",
      "| eplenmean               | 3.61      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 28.5      |\n",
      "| n_updates               | 796200    |\n",
      "| qf1_loss                | 374.2418  |\n",
      "| qf2_loss                | 369.83676 |\n",
      "| time_elapsed            | 74008     |\n",
      "| total timesteps         | 796367    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 20.9      |\n",
      "| episodes                | 230000    |\n",
      "| eplenmean               | 3.58      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 20.9      |\n",
      "| n_updates               | 813900    |\n",
      "| qf1_loss                | 371.7114  |\n",
      "| qf2_loss                | 369.95605 |\n",
      "| time_elapsed            | 75658     |\n",
      "| total timesteps         | 814091    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 19.7      |\n",
      "| episodes                | 235000    |\n",
      "| eplenmean               | 3.57      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 19.7      |\n",
      "| n_updates               | 831500    |\n",
      "| qf1_loss                | 366.22446 |\n",
      "| qf2_loss                | 363.82062 |\n",
      "| time_elapsed            | 77288     |\n",
      "| total timesteps         | 831685    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 13.6      |\n",
      "| episodes                | 240000    |\n",
      "| eplenmean               | 3.16      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 13.6      |\n",
      "| n_updates               | 849000    |\n",
      "| qf1_loss                | 371.10614 |\n",
      "| qf2_loss                | 373.10837 |\n",
      "| time_elapsed            | 78931     |\n",
      "| total timesteps         | 849120    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 16.3      |\n",
      "| episodes                | 245000    |\n",
      "| eplenmean               | 3.29      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 16.3      |\n",
      "| n_updates               | 866300    |\n",
      "| qf1_loss                | 390.55408 |\n",
      "| qf2_loss                | 384.79892 |\n",
      "| time_elapsed            | 80551     |\n",
      "| total timesteps         | 866494    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 20.7      |\n",
      "| episodes                | 250000    |\n",
      "| eplenmean               | 3.48      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 20.7      |\n",
      "| n_updates               | 883800    |\n",
      "| qf1_loss                | 381.12268 |\n",
      "| qf2_loss                | 388.49    |\n",
      "| time_elapsed            | 82177     |\n",
      "| total timesteps         | 883916    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 21.7     |\n",
      "| episodes                | 255000   |\n",
      "| eplenmean               | 3.39     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 21.7     |\n",
      "| n_updates               | 901300   |\n",
      "| qf1_loss                | 361.035  |\n",
      "| qf2_loss                | 361.6643 |\n",
      "| time_elapsed            | 83821    |\n",
      "| total timesteps         | 901466   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 20.6      |\n",
      "| episodes                | 260000    |\n",
      "| eplenmean               | 3.19      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 20.6      |\n",
      "| n_updates               | 918600    |\n",
      "| qf1_loss                | 368.26508 |\n",
      "| qf2_loss                | 370.5241  |\n",
      "| time_elapsed            | 85453     |\n",
      "| total timesteps         | 918765    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 23.8      |\n",
      "| episodes                | 265000    |\n",
      "| eplenmean               | 3.33      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 23.8      |\n",
      "| n_updates               | 935400    |\n",
      "| qf1_loss                | 351.46262 |\n",
      "| qf2_loss                | 355.92593 |\n",
      "| time_elapsed            | 87066     |\n",
      "| total timesteps         | 935511    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 29.5      |\n",
      "| episodes                | 270000    |\n",
      "| eplenmean               | 3.69      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 29.5      |\n",
      "| n_updates               | 952400    |\n",
      "| qf1_loss                | 378.1534  |\n",
      "| qf2_loss                | 371.92087 |\n",
      "| time_elapsed            | 88677     |\n",
      "| total timesteps         | 952571    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 19.5      |\n",
      "| episodes                | 275000    |\n",
      "| eplenmean               | 3.36      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 19.5      |\n",
      "| n_updates               | 969700    |\n",
      "| qf1_loss                | 367.30124 |\n",
      "| qf2_loss                | 363.20126 |\n",
      "| time_elapsed            | 90300     |\n",
      "| total timesteps         | 969829    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.1      |\n",
      "| episodes                | 280000    |\n",
      "| eplenmean               | 2.87      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.1      |\n",
      "| n_updates               | 986900    |\n",
      "| qf1_loss                | 378.60574 |\n",
      "| qf2_loss                | 380.54636 |\n",
      "| time_elapsed            | 91938     |\n",
      "| total timesteps         | 987054    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.td3.td3.TD3 at 0x1e54e418a08>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=int(1e6), log_interval=5000, callback=[checkpoint_callback,eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(checkpoint_path+\"end_manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
