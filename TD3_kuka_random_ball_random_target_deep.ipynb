{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines import TD3\n",
    "from stable_baselines.td3.policies import LnMlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.ddpg.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "from stable_baselines.common.callbacks import CheckpointCallback, EvalCallback\n",
    "from stable_baselines.bench import Monitor\n",
    "\n",
    "from modules import CustomTD3Policy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from modules import KukaBulletGymRandomBallRandomTarget\n",
    "\n",
    "import os\n",
    "\n",
    "# Reloading any code written in external .py files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging and saving directories\n",
    "parent = \"./TD3_kuka_random_ball_random_target_deep/\"\n",
    "checkpoint_path = parent + \"checkpoints/\"\n",
    "best_model_path = parent + \"best_model/\"\n",
    "eval_log_path = parent + \"eval_logs/\"\n",
    "monitor_log_path = parent + \"monitor_logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make environment with monitor wrapper\n",
    "env = KukaBulletGymRandomBallRandomTarget.KukaBulletGym(render=False)\n",
    "wrapped_env = Monitor(env, monitor_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make callbacks\n",
    "checkpoint_callback = CheckpointCallback(save_freq=50000, \n",
    "                                         save_path=checkpoint_path,\n",
    "                                         name_prefix=\"model\")\n",
    "eval_callback = EvalCallback(env,\n",
    "                             best_model_save_path=best_model_path, \n",
    "                             log_path=eval_log_path,\n",
    "                             eval_freq=1000, \n",
    "                             deterministic=True, \n",
    "                             render=False,\n",
    "                             verbose=0,\n",
    "                             n_eval_episodes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "model = TD3.load(\"./TD3_kuka_random_ball_deep/best_model/best_model\")\n",
    "model.set_env(wrapped_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\stable_bl\\lib\\site-packages\\stable_baselines\\common\\callbacks.py:277: UserWarning: Training and eval env are not of the same type<Monitor<KukaBulletGym instance>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x000002D658F9F048>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 5.1       |\n",
      "| episodes                | 5000      |\n",
      "| eplenmean               | 4.18      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 5.1       |\n",
      "| n_updates               | 21000     |\n",
      "| qf1_loss                | 43.13892  |\n",
      "| qf2_loss                | 46.031143 |\n",
      "| time_elapsed            | 1957      |\n",
      "| total timesteps         | 21189     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 7.47      |\n",
      "| episodes                | 10000     |\n",
      "| eplenmean               | 4.02      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 7.5       |\n",
      "| n_updates               | 41600     |\n",
      "| qf1_loss                | 60.2952   |\n",
      "| qf2_loss                | 60.879227 |\n",
      "| time_elapsed            | 3885      |\n",
      "| total timesteps         | 41792     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 3.09      |\n",
      "| episodes                | 15000     |\n",
      "| eplenmean               | 4.17      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 3.1       |\n",
      "| n_updates               | 62200     |\n",
      "| qf1_loss                | 69.37459  |\n",
      "| qf2_loss                | 66.928795 |\n",
      "| time_elapsed            | 5825      |\n",
      "| total timesteps         | 62369     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.21      |\n",
      "| episodes                | 20000     |\n",
      "| eplenmean               | 4.12      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.2       |\n",
      "| n_updates               | 82900     |\n",
      "| qf1_loss                | 63.690918 |\n",
      "| qf2_loss                | 60.229565 |\n",
      "| time_elapsed            | 7771      |\n",
      "| total timesteps         | 83096     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 4.13      |\n",
      "| episodes                | 25000     |\n",
      "| eplenmean               | 4.08      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 4.1       |\n",
      "| n_updates               | 103200    |\n",
      "| qf1_loss                | 57.95727  |\n",
      "| qf2_loss                | 59.973404 |\n",
      "| time_elapsed            | 9691      |\n",
      "| total timesteps         | 103382    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 5.47      |\n",
      "| episodes                | 30000     |\n",
      "| eplenmean               | 4.04      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 5.5       |\n",
      "| n_updates               | 123400    |\n",
      "| qf1_loss                | 73.09665  |\n",
      "| qf2_loss                | 77.948906 |\n",
      "| time_elapsed            | 11602     |\n",
      "| total timesteps         | 123556    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 6.34     |\n",
      "| episodes                | 35000    |\n",
      "| eplenmean               | 3.98     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 6.3      |\n",
      "| n_updates               | 143700   |\n",
      "| qf1_loss                | 80.48334 |\n",
      "| qf2_loss                | 80.75489 |\n",
      "| time_elapsed            | 13512    |\n",
      "| total timesteps         | 143850   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 4.67      |\n",
      "| episodes                | 40000     |\n",
      "| eplenmean               | 3.99      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 4.7       |\n",
      "| n_updates               | 163600    |\n",
      "| qf1_loss                | 84.139755 |\n",
      "| qf2_loss                | 78.18139  |\n",
      "| time_elapsed            | 15412     |\n",
      "| total timesteps         | 163742    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ep_rewmean              | 4.35       |\n",
      "| episodes                | 45000      |\n",
      "| eplenmean               | 4.12       |\n",
      "| fps                     | 10         |\n",
      "| mean 100 episode reward | 4.4        |\n",
      "| n_updates               | 183900     |\n",
      "| qf1_loss                | 94.84634   |\n",
      "| qf2_loss                | 100.307785 |\n",
      "| time_elapsed            | 17345      |\n",
      "| total timesteps         | 184087     |\n",
      "----------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ep_rewmean              | 4.35       |\n",
      "| episodes                | 50000      |\n",
      "| eplenmean               | 4.08       |\n",
      "| fps                     | 10         |\n",
      "| mean 100 episode reward | 4.3        |\n",
      "| n_updates               | 204400     |\n",
      "| qf1_loss                | 103.397766 |\n",
      "| qf2_loss                | 92.31979   |\n",
      "| time_elapsed            | 19263      |\n",
      "| total timesteps         | 204520     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.23      |\n",
      "| episodes                | 55000     |\n",
      "| eplenmean               | 4.06      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.2       |\n",
      "| n_updates               | 224800    |\n",
      "| qf1_loss                | 90.78877  |\n",
      "| qf2_loss                | 89.226036 |\n",
      "| time_elapsed            | 21174     |\n",
      "| total timesteps         | 224941    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 7.81      |\n",
      "| episodes                | 60000     |\n",
      "| eplenmean               | 4.1       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 7.8       |\n",
      "| n_updates               | 245300    |\n",
      "| qf1_loss                | 75.988976 |\n",
      "| qf2_loss                | 72.45266  |\n",
      "| time_elapsed            | 23114     |\n",
      "| total timesteps         | 245482    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 5.58     |\n",
      "| episodes                | 65000    |\n",
      "| eplenmean               | 4.16     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 5.6      |\n",
      "| n_updates               | 265900   |\n",
      "| qf1_loss                | 78.49052 |\n",
      "| qf2_loss                | 73.05533 |\n",
      "| time_elapsed            | 25054    |\n",
      "| total timesteps         | 266049   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 5.45      |\n",
      "| episodes                | 70000     |\n",
      "| eplenmean               | 4.09      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 5.4       |\n",
      "| n_updates               | 286400    |\n",
      "| qf1_loss                | 81.645775 |\n",
      "| qf2_loss                | 82.287285 |\n",
      "| time_elapsed            | 26967     |\n",
      "| total timesteps         | 286521    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 1.04      |\n",
      "| episodes                | 75000     |\n",
      "| eplenmean               | 4.06      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 1         |\n",
      "| n_updates               | 306800    |\n",
      "| qf1_loss                | 93.723785 |\n",
      "| qf2_loss                | 79.93896  |\n",
      "| time_elapsed            | 28891     |\n",
      "| total timesteps         | 306983    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 5.39     |\n",
      "| episodes                | 80000    |\n",
      "| eplenmean               | 4.21     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 5.4      |\n",
      "| n_updates               | 327300   |\n",
      "| qf1_loss                | 94.85736 |\n",
      "| qf2_loss                | 99.99905 |\n",
      "| time_elapsed            | 30822    |\n",
      "| total timesteps         | 327443   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 9.92     |\n",
      "| episodes                | 85000    |\n",
      "| eplenmean               | 4.1      |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 9.9      |\n",
      "| n_updates               | 348000   |\n",
      "| qf1_loss                | 89.82968 |\n",
      "| qf2_loss                | 84.81124 |\n",
      "| time_elapsed            | 32761    |\n",
      "| total timesteps         | 348125   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 5.4      |\n",
      "| episodes                | 90000    |\n",
      "| eplenmean               | 4.05     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 5.4      |\n",
      "| n_updates               | 368600   |\n",
      "| qf1_loss                | 89.4835  |\n",
      "| qf2_loss                | 81.71107 |\n",
      "| time_elapsed            | 34679    |\n",
      "| total timesteps         | 368778   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 8.84     |\n",
      "| episodes                | 95000    |\n",
      "| eplenmean               | 4.06     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 8.8      |\n",
      "| n_updates               | 389000   |\n",
      "| qf1_loss                | 94.77839 |\n",
      "| qf2_loss                | 87.55414 |\n",
      "| time_elapsed            | 36605    |\n",
      "| total timesteps         | 389129   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 6.88      |\n",
      "| episodes                | 100000    |\n",
      "| eplenmean               | 4.08      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 6.9       |\n",
      "| n_updates               | 409200    |\n",
      "| qf1_loss                | 96.567894 |\n",
      "| qf2_loss                | 94.41674  |\n",
      "| time_elapsed            | 38507     |\n",
      "| total timesteps         | 409390    |\n",
      "---------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ep_rewmean              | 5.36       |\n",
      "| episodes                | 105000     |\n",
      "| eplenmean               | 4.12       |\n",
      "| fps                     | 10         |\n",
      "| mean 100 episode reward | 5.4        |\n",
      "| n_updates               | 429600     |\n",
      "| qf1_loss                | 103.620674 |\n",
      "| qf2_loss                | 100.452354 |\n",
      "| time_elapsed            | 40417      |\n",
      "| total timesteps         | 429751     |\n",
      "----------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 4.59     |\n",
      "| episodes                | 110000   |\n",
      "| eplenmean               | 4.12     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 4.6      |\n",
      "| n_updates               | 450100   |\n",
      "| qf1_loss                | 83.63054 |\n",
      "| qf2_loss                | 85.91971 |\n",
      "| time_elapsed            | 42354    |\n",
      "| total timesteps         | 450286   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 4.5      |\n",
      "| episodes                | 115000   |\n",
      "| eplenmean               | 4.07     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 4.5      |\n",
      "| n_updates               | 470600   |\n",
      "| qf1_loss                | 90.80762 |\n",
      "| qf2_loss                | 79.63033 |\n",
      "| time_elapsed            | 44261    |\n",
      "| total timesteps         | 470729   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 6.25     |\n",
      "| episodes                | 120000   |\n",
      "| eplenmean               | 4.12     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 6.2      |\n",
      "| n_updates               | 490900   |\n",
      "| qf1_loss                | 75.79462 |\n",
      "| qf2_loss                | 73.96807 |\n",
      "| time_elapsed            | 46182    |\n",
      "| total timesteps         | 491061   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 5.3       |\n",
      "| episodes                | 125000    |\n",
      "| eplenmean               | 4.06      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 5.3       |\n",
      "| n_updates               | 511300    |\n",
      "| qf1_loss                | 62.932907 |\n",
      "| qf2_loss                | 59.348812 |\n",
      "| time_elapsed            | 48090     |\n",
      "| total timesteps         | 511500    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 6.53      |\n",
      "| episodes                | 130000    |\n",
      "| eplenmean               | 4.15      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 6.5       |\n",
      "| n_updates               | 531800    |\n",
      "| qf1_loss                | 88.120155 |\n",
      "| qf2_loss                | 87.17614  |\n",
      "| time_elapsed            | 49873     |\n",
      "| total timesteps         | 531946    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 6.28      |\n",
      "| episodes                | 135000    |\n",
      "| eplenmean               | 4.06      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 6.3       |\n",
      "| n_updates               | 552100    |\n",
      "| qf1_loss                | 71.695175 |\n",
      "| qf2_loss                | 72.86284  |\n",
      "| time_elapsed            | 51603     |\n",
      "| total timesteps         | 552272    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 8.87      |\n",
      "| episodes                | 140000    |\n",
      "| eplenmean               | 4.01      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 8.9       |\n",
      "| n_updates               | 572300    |\n",
      "| qf1_loss                | 80.91493  |\n",
      "| qf2_loss                | 103.97001 |\n",
      "| time_elapsed            | 53322     |\n",
      "| total timesteps         | 572429    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 5.7       |\n",
      "| episodes                | 145000    |\n",
      "| eplenmean               | 4.01      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 5.7       |\n",
      "| n_updates               | 592400    |\n",
      "| qf1_loss                | 97.98358  |\n",
      "| qf2_loss                | 100.18786 |\n",
      "| time_elapsed            | 55201     |\n",
      "| total timesteps         | 592581    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 8.13      |\n",
      "| episodes                | 150000    |\n",
      "| eplenmean               | 4.12      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 8.1       |\n",
      "| n_updates               | 612700    |\n",
      "| qf1_loss                | 93.22604  |\n",
      "| qf2_loss                | 92.848976 |\n",
      "| time_elapsed            | 57102     |\n",
      "| total timesteps         | 612867    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 8.57     |\n",
      "| episodes                | 155000   |\n",
      "| eplenmean               | 4.26     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 8.6      |\n",
      "| n_updates               | 633900   |\n",
      "| qf1_loss                | 77.89493 |\n",
      "| qf2_loss                | 82.91747 |\n",
      "| time_elapsed            | 59083    |\n",
      "| total timesteps         | 634083   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 8.76     |\n",
      "| episodes                | 160000   |\n",
      "| eplenmean               | 4.1      |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 8.8      |\n",
      "| n_updates               | 654500   |\n",
      "| qf1_loss                | 83.8328  |\n",
      "| qf2_loss                | 84.73695 |\n",
      "| time_elapsed            | 61005    |\n",
      "| total timesteps         | 654648   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 7.52     |\n",
      "| episodes                | 165000   |\n",
      "| eplenmean               | 4.13     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 7.5      |\n",
      "| n_updates               | 674700   |\n",
      "| qf1_loss                | 66.71635 |\n",
      "| qf2_loss                | 67.75067 |\n",
      "| time_elapsed            | 62911    |\n",
      "| total timesteps         | 674825   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.05      |\n",
      "| episodes                | 170000    |\n",
      "| eplenmean               | 4.54      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2         |\n",
      "| n_updates               | 695200    |\n",
      "| qf1_loss                | 57.258488 |\n",
      "| qf2_loss                | 53.62899  |\n",
      "| time_elapsed            | 64846     |\n",
      "| total timesteps         | 695391    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.13      |\n",
      "| episodes                | 175000    |\n",
      "| eplenmean               | 4.06      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.1       |\n",
      "| n_updates               | 715900    |\n",
      "| qf1_loss                | 53.239838 |\n",
      "| qf2_loss                | 50.699207 |\n",
      "| time_elapsed            | 66787     |\n",
      "| total timesteps         | 716072    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 1.77      |\n",
      "| episodes                | 180000    |\n",
      "| eplenmean               | 3.94      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 1.8       |\n",
      "| n_updates               | 735700    |\n",
      "| qf1_loss                | 62.499744 |\n",
      "| qf2_loss                | 52.026688 |\n",
      "| time_elapsed            | 68651     |\n",
      "| total timesteps         | 735806    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 5.33      |\n",
      "| episodes                | 185000    |\n",
      "| eplenmean               | 4.14      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 5.3       |\n",
      "| n_updates               | 756100    |\n",
      "| qf1_loss                | 64.79705  |\n",
      "| qf2_loss                | 51.931427 |\n",
      "| time_elapsed            | 70572     |\n",
      "| total timesteps         | 756265    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 5.34      |\n",
      "| episodes                | 190000    |\n",
      "| eplenmean               | 4.16      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 5.3       |\n",
      "| n_updates               | 776800    |\n",
      "| qf1_loss                | 74.480385 |\n",
      "| qf2_loss                | 73.83537  |\n",
      "| time_elapsed            | 72487     |\n",
      "| total timesteps         | 776950    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 1.98      |\n",
      "| episodes                | 195000    |\n",
      "| eplenmean               | 4.22      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2         |\n",
      "| n_updates               | 797800    |\n",
      "| qf1_loss                | 73.65321  |\n",
      "| qf2_loss                | 77.624565 |\n",
      "| time_elapsed            | 74477     |\n",
      "| total timesteps         | 797924    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 8.61      |\n",
      "| episodes                | 200000    |\n",
      "| eplenmean               | 4.08      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 8.6       |\n",
      "| n_updates               | 818300    |\n",
      "| qf1_loss                | 76.580734 |\n",
      "| qf2_loss                | 75.68997  |\n",
      "| time_elapsed            | 76415     |\n",
      "| total timesteps         | 818460    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 9.77     |\n",
      "| episodes                | 205000   |\n",
      "| eplenmean               | 4.12     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 9.8      |\n",
      "| n_updates               | 838700   |\n",
      "| qf1_loss                | 78.12866 |\n",
      "| qf2_loss                | 78.84158 |\n",
      "| time_elapsed            | 78316    |\n",
      "| total timesteps         | 838843   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 9.88      |\n",
      "| episodes                | 210000    |\n",
      "| eplenmean               | 4.17      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 9.9       |\n",
      "| n_updates               | 859100    |\n",
      "| qf1_loss                | 74.188934 |\n",
      "| qf2_loss                | 77.831345 |\n",
      "| time_elapsed            | 80235     |\n",
      "| total timesteps         | 859253    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 4.6      |\n",
      "| episodes                | 215000   |\n",
      "| eplenmean               | 3.81     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 4.6      |\n",
      "| n_updates               | 879500   |\n",
      "| qf1_loss                | 72.08582 |\n",
      "| qf2_loss                | 67.30899 |\n",
      "| time_elapsed            | 82139    |\n",
      "| total timesteps         | 879650   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.14      |\n",
      "| episodes                | 220000    |\n",
      "| eplenmean               | 3.41      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.1       |\n",
      "| n_updates               | 897600    |\n",
      "| qf1_loss                | 46.538116 |\n",
      "| qf2_loss                | 38.116146 |\n",
      "| time_elapsed            | 83934     |\n",
      "| total timesteps         | 897799    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 5.59     |\n",
      "| episodes                | 225000   |\n",
      "| eplenmean               | 4.09     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 5.6      |\n",
      "| n_updates               | 916500   |\n",
      "| qf1_loss                | 54.03507 |\n",
      "| qf2_loss                | 50.67344 |\n",
      "| time_elapsed            | 85768    |\n",
      "| total timesteps         | 916625   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 6.81      |\n",
      "| episodes                | 230000    |\n",
      "| eplenmean               | 4.11      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 6.8       |\n",
      "| n_updates               | 936600    |\n",
      "| qf1_loss                | 75.26871  |\n",
      "| qf2_loss                | 71.249695 |\n",
      "| time_elapsed            | 87669     |\n",
      "| total timesteps         | 936765    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 4.34      |\n",
      "| episodes                | 235000    |\n",
      "| eplenmean               | 4.16      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 4.3       |\n",
      "| n_updates               | 957200    |\n",
      "| qf1_loss                | 80.66473  |\n",
      "| qf2_loss                | 78.576385 |\n",
      "| time_elapsed            | 89604     |\n",
      "| total timesteps         | 957339    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.19      |\n",
      "| episodes                | 240000    |\n",
      "| eplenmean               | 4.12      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.2       |\n",
      "| n_updates               | 977800    |\n",
      "| qf1_loss                | 74.268555 |\n",
      "| qf2_loss                | 73.64123  |\n",
      "| time_elapsed            | 91517     |\n",
      "| total timesteps         | 977918    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 3.04     |\n",
      "| episodes                | 245000   |\n",
      "| eplenmean               | 4.16     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 3        |\n",
      "| n_updates               | 998000   |\n",
      "| qf1_loss                | 46.32652 |\n",
      "| qf2_loss                | 49.93143 |\n",
      "| time_elapsed            | 93430    |\n",
      "| total timesteps         | 998160   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.td3.td3.TD3 at 0x2d658ec62c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=int(1e6), log_interval=5000, callback=[checkpoint_callback,eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(checkpoint_path+\"end_manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
