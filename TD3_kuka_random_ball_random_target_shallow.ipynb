{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines import TD3\n",
    "from stable_baselines.td3.policies import LnMlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.ddpg.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "from stable_baselines.common.callbacks import CheckpointCallback, EvalCallback\n",
    "from stable_baselines.bench import Monitor\n",
    "\n",
    "from modules import CustomTD3Policy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from modules import KukaBulletGymRandomBallRandomTarget\n",
    "\n",
    "import os\n",
    "\n",
    "# Reloading any code written in external .py files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging and saving directories\n",
    "parent = \"./TD3_kuka_random_ball_random_target_shallow/\"\n",
    "checkpoint_path = parent + \"checkpoints/\"\n",
    "best_model_path = parent + \"best_model/\"\n",
    "eval_log_path = parent + \"eval_logs/\"\n",
    "monitor_log_path = parent + \"monitor_logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make environment with monitor wrapper\n",
    "env = KukaBulletGymRandomBallRandomTarget.KukaBulletGym(render=False)\n",
    "wrapped_env = Monitor(env, monitor_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make callbacks\n",
    "checkpoint_callback = CheckpointCallback(save_freq=50000, \n",
    "                                         save_path=checkpoint_path,\n",
    "                                         name_prefix=\"model\")\n",
    "eval_callback = EvalCallback(env,\n",
    "                             best_model_save_path=best_model_path, \n",
    "                             log_path=eval_log_path,\n",
    "                             eval_freq=1000, \n",
    "                             deterministic=True, \n",
    "                             render=False,\n",
    "                             verbose=0,\n",
    "                             n_eval_episodes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "model = TD3.load(\"./TD3_kuka_random_ball_shallow/best_model/best_model\")\n",
    "model.set_env(wrapped_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\stable_bl\\lib\\site-packages\\stable_baselines\\common\\callbacks.py:277: UserWarning: Training and eval env are not of the same type<Monitor<KukaBulletGym instance>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000206CA8C7248>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 12        |\n",
      "| episodes                | 5000      |\n",
      "| eplenmean               | 3.05      |\n",
      "| fps                     | 9         |\n",
      "| mean 100 episode reward | 12        |\n",
      "| n_updates               | 14000     |\n",
      "| qf1_loss                | 175.9384  |\n",
      "| qf2_loss                | 176.35236 |\n",
      "| time_elapsed            | 1490      |\n",
      "| total timesteps         | 14183     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 19        |\n",
      "| episodes                | 10000     |\n",
      "| eplenmean               | 4.3       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 19        |\n",
      "| n_updates               | 31900     |\n",
      "| qf1_loss                | 222.17229 |\n",
      "| qf2_loss                | 227.36511 |\n",
      "| time_elapsed            | 3129      |\n",
      "| total timesteps         | 32025     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 10.8      |\n",
      "| episodes                | 15000     |\n",
      "| eplenmean               | 3.55      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 10.8      |\n",
      "| n_updates               | 50600     |\n",
      "| qf1_loss                | 245.77644 |\n",
      "| qf2_loss                | 251.36665 |\n",
      "| time_elapsed            | 4791      |\n",
      "| total timesteps         | 50790     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 15.4      |\n",
      "| episodes                | 20000     |\n",
      "| eplenmean               | 3.74      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 15.4      |\n",
      "| n_updates               | 69300     |\n",
      "| qf1_loss                | 285.22958 |\n",
      "| qf2_loss                | 273.6957  |\n",
      "| time_elapsed            | 6472      |\n",
      "| total timesteps         | 69460     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 9.23      |\n",
      "| episodes                | 25000     |\n",
      "| eplenmean               | 3.86      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 9.2       |\n",
      "| n_updates               | 88200     |\n",
      "| qf1_loss                | 299.77335 |\n",
      "| qf2_loss                | 297.22134 |\n",
      "| time_elapsed            | 8152      |\n",
      "| total timesteps         | 88343     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 20.8      |\n",
      "| episodes                | 30000     |\n",
      "| eplenmean               | 3.58      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 20.8      |\n",
      "| n_updates               | 106000    |\n",
      "| qf1_loss                | 313.2655  |\n",
      "| qf2_loss                | 310.14804 |\n",
      "| time_elapsed            | 9795      |\n",
      "| total timesteps         | 106195    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 14.6      |\n",
      "| episodes                | 35000     |\n",
      "| eplenmean               | 3.61      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 14.6      |\n",
      "| n_updates               | 122500    |\n",
      "| qf1_loss                | 290.78793 |\n",
      "| qf2_loss                | 281.7829  |\n",
      "| time_elapsed            | 11372     |\n",
      "| total timesteps         | 122648    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 9.68      |\n",
      "| episodes                | 40000     |\n",
      "| eplenmean               | 3.1       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 9.7       |\n",
      "| n_updates               | 140300    |\n",
      "| qf1_loss                | 293.4302  |\n",
      "| qf2_loss                | 285.16446 |\n",
      "| time_elapsed            | 13012     |\n",
      "| total timesteps         | 140461    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 19.5      |\n",
      "| episodes                | 45000     |\n",
      "| eplenmean               | 3.76      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 19.5      |\n",
      "| n_updates               | 157600    |\n",
      "| qf1_loss                | 283.12314 |\n",
      "| qf2_loss                | 271.23486 |\n",
      "| time_elapsed            | 14618     |\n",
      "| total timesteps         | 157763    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 7.25      |\n",
      "| episodes                | 50000     |\n",
      "| eplenmean               | 2.98      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 7.3       |\n",
      "| n_updates               | 174000    |\n",
      "| qf1_loss                | 266.6871  |\n",
      "| qf2_loss                | 270.54556 |\n",
      "| time_elapsed            | 16213     |\n",
      "| total timesteps         | 174142    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 9.85      |\n",
      "| episodes                | 55000     |\n",
      "| eplenmean               | 3.29      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 9.9       |\n",
      "| n_updates               | 190700    |\n",
      "| qf1_loss                | 275.73337 |\n",
      "| qf2_loss                | 270.34113 |\n",
      "| time_elapsed            | 17795     |\n",
      "| total timesteps         | 190806    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 15        |\n",
      "| episodes                | 60000     |\n",
      "| eplenmean               | 3.3       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 15        |\n",
      "| n_updates               | 207500    |\n",
      "| qf1_loss                | 279.55164 |\n",
      "| qf2_loss                | 263.2754  |\n",
      "| time_elapsed            | 19402     |\n",
      "| total timesteps         | 207620    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 13        |\n",
      "| episodes                | 65000     |\n",
      "| eplenmean               | 3.43      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 13        |\n",
      "| n_updates               | 224400    |\n",
      "| qf1_loss                | 276.60547 |\n",
      "| qf2_loss                | 261.02927 |\n",
      "| time_elapsed            | 21069     |\n",
      "| total timesteps         | 224574    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.2      |\n",
      "| episodes                | 70000     |\n",
      "| eplenmean               | 3.29      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.2      |\n",
      "| n_updates               | 241700    |\n",
      "| qf1_loss                | 253.58344 |\n",
      "| qf2_loss                | 250.10449 |\n",
      "| time_elapsed            | 22677     |\n",
      "| total timesteps         | 241851    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 10.8      |\n",
      "| episodes                | 75000     |\n",
      "| eplenmean               | 3.03      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 10.8      |\n",
      "| n_updates               | 258900    |\n",
      "| qf1_loss                | 255.45717 |\n",
      "| qf2_loss                | 253.4387  |\n",
      "| time_elapsed            | 24306     |\n",
      "| total timesteps         | 259017    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 20.8      |\n",
      "| episodes                | 80000     |\n",
      "| eplenmean               | 3.49      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 20.8      |\n",
      "| n_updates               | 276300    |\n",
      "| qf1_loss                | 247.363   |\n",
      "| qf2_loss                | 236.19888 |\n",
      "| time_elapsed            | 25918     |\n",
      "| total timesteps         | 276450    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 11.6      |\n",
      "| episodes                | 85000     |\n",
      "| eplenmean               | 3.27      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 11.6      |\n",
      "| n_updates               | 294300    |\n",
      "| qf1_loss                | 254.90883 |\n",
      "| qf2_loss                | 238.1889  |\n",
      "| time_elapsed            | 27560     |\n",
      "| total timesteps         | 294475    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 16.2      |\n",
      "| episodes                | 90000     |\n",
      "| eplenmean               | 3.48      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 16.2      |\n",
      "| n_updates               | 311100    |\n",
      "| qf1_loss                | 255.85092 |\n",
      "| qf2_loss                | 248.29164 |\n",
      "| time_elapsed            | 29155     |\n",
      "| total timesteps         | 311254    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 19.6      |\n",
      "| episodes                | 95000     |\n",
      "| eplenmean               | 3.27      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 19.6      |\n",
      "| n_updates               | 327400    |\n",
      "| qf1_loss                | 253.58803 |\n",
      "| qf2_loss                | 244.47197 |\n",
      "| time_elapsed            | 30717     |\n",
      "| total timesteps         | 327543    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 16.4      |\n",
      "| episodes                | 100000    |\n",
      "| eplenmean               | 3.66      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 16.4      |\n",
      "| n_updates               | 344600    |\n",
      "| qf1_loss                | 268.31613 |\n",
      "| qf2_loss                | 265.66962 |\n",
      "| time_elapsed            | 32322     |\n",
      "| total timesteps         | 344719    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.9      |\n",
      "| episodes                | 105000    |\n",
      "| eplenmean               | 3.57      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.9      |\n",
      "| n_updates               | 362300    |\n",
      "| qf1_loss                | 253.50816 |\n",
      "| qf2_loss                | 255.89851 |\n",
      "| time_elapsed            | 33958     |\n",
      "| total timesteps         | 362431    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 13.3      |\n",
      "| episodes                | 110000    |\n",
      "| eplenmean               | 3.66      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 13.3      |\n",
      "| n_updates               | 380200    |\n",
      "| qf1_loss                | 260.29056 |\n",
      "| qf2_loss                | 258.22882 |\n",
      "| time_elapsed            | 35598     |\n",
      "| total timesteps         | 380395    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.3      |\n",
      "| episodes                | 115000    |\n",
      "| eplenmean               | 3.77      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.3      |\n",
      "| n_updates               | 397800    |\n",
      "| qf1_loss                | 273.19833 |\n",
      "| qf2_loss                | 263.4941  |\n",
      "| time_elapsed            | 37212     |\n",
      "| total timesteps         | 397995    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.215     |\n",
      "| episodes                | 120000    |\n",
      "| eplenmean               | 1.42      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.2       |\n",
      "| n_updates               | 412800    |\n",
      "| qf1_loss                | 273.4616  |\n",
      "| qf2_loss                | 268.11368 |\n",
      "| time_elapsed            | 38739     |\n",
      "| total timesteps         | 412908    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.5      |\n",
      "| episodes                | 125000    |\n",
      "| eplenmean               | 3.43      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.5      |\n",
      "| n_updates               | 430000    |\n",
      "| qf1_loss                | 277.18036 |\n",
      "| qf2_loss                | 268.79532 |\n",
      "| time_elapsed            | 40251     |\n",
      "| total timesteps         | 430184    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 19.9      |\n",
      "| episodes                | 130000    |\n",
      "| eplenmean               | 3.47      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 19.9      |\n",
      "| n_updates               | 447800    |\n",
      "| qf1_loss                | 291.61856 |\n",
      "| qf2_loss                | 286.12442 |\n",
      "| time_elapsed            | 41658     |\n",
      "| total timesteps         | 447968    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 22.2      |\n",
      "| episodes                | 135000    |\n",
      "| eplenmean               | 3.67      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 22.2      |\n",
      "| n_updates               | 466100    |\n",
      "| qf1_loss                | 315.85864 |\n",
      "| qf2_loss                | 306.31683 |\n",
      "| time_elapsed            | 43213     |\n",
      "| total timesteps         | 466278    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 22.6      |\n",
      "| episodes                | 140000    |\n",
      "| eplenmean               | 3.4       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 22.6      |\n",
      "| n_updates               | 484100    |\n",
      "| qf1_loss                | 317.7379  |\n",
      "| qf2_loss                | 310.01385 |\n",
      "| time_elapsed            | 44818     |\n",
      "| total timesteps         | 484273    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 13.8      |\n",
      "| episodes                | 145000    |\n",
      "| eplenmean               | 3.24      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 13.8      |\n",
      "| n_updates               | 501800    |\n",
      "| qf1_loss                | 307.20813 |\n",
      "| qf2_loss                | 305.3618  |\n",
      "| time_elapsed            | 46955     |\n",
      "| total timesteps         | 501982    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 18.2      |\n",
      "| episodes                | 150000    |\n",
      "| eplenmean               | 3.21      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 18.2      |\n",
      "| n_updates               | 518900    |\n",
      "| qf1_loss                | 299.7909  |\n",
      "| qf2_loss                | 298.96933 |\n",
      "| time_elapsed            | 49094     |\n",
      "| total timesteps         | 519035    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 21        |\n",
      "| episodes                | 155000    |\n",
      "| eplenmean               | 3.53      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 21        |\n",
      "| n_updates               | 535900    |\n",
      "| qf1_loss                | 302.71997 |\n",
      "| qf2_loss                | 301.52283 |\n",
      "| time_elapsed            | 50841     |\n",
      "| total timesteps         | 536075    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 23.2      |\n",
      "| episodes                | 160000    |\n",
      "| eplenmean               | 3.49      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 23.2      |\n",
      "| n_updates               | 553100    |\n",
      "| qf1_loss                | 314.98492 |\n",
      "| qf2_loss                | 309.95673 |\n",
      "| time_elapsed            | 52963     |\n",
      "| total timesteps         | 553230    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 15.3      |\n",
      "| episodes                | 165000    |\n",
      "| eplenmean               | 3.4       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 15.3      |\n",
      "| n_updates               | 570400    |\n",
      "| qf1_loss                | 304.85403 |\n",
      "| qf2_loss                | 301.34433 |\n",
      "| time_elapsed            | 54836     |\n",
      "| total timesteps         | 570509    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 23.2     |\n",
      "| episodes                | 170000   |\n",
      "| eplenmean               | 3.51     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 23.2     |\n",
      "| n_updates               | 587300   |\n",
      "| qf1_loss                | 328.8575 |\n",
      "| qf2_loss                | 324.33   |\n",
      "| time_elapsed            | 56557    |\n",
      "| total timesteps         | 587457   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 22.8      |\n",
      "| episodes                | 175000    |\n",
      "| eplenmean               | 3.52      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 22.8      |\n",
      "| n_updates               | 604500    |\n",
      "| qf1_loss                | 324.26047 |\n",
      "| qf2_loss                | 319.82483 |\n",
      "| time_elapsed            | 58207     |\n",
      "| total timesteps         | 604627    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 22.2      |\n",
      "| episodes                | 180000    |\n",
      "| eplenmean               | 3.44      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 22.2      |\n",
      "| n_updates               | 621900    |\n",
      "| qf1_loss                | 319.59927 |\n",
      "| qf2_loss                | 314.20142 |\n",
      "| time_elapsed            | 59878     |\n",
      "| total timesteps         | 622094    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.159     |\n",
      "| episodes                | 185000    |\n",
      "| eplenmean               | 2         |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.2       |\n",
      "| n_updates               | 632200    |\n",
      "| qf1_loss                | 252.67743 |\n",
      "| qf2_loss                | 253.41922 |\n",
      "| time_elapsed            | 61231     |\n",
      "| total timesteps         | 632327    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.159     |\n",
      "| episodes                | 190000    |\n",
      "| eplenmean               | 2         |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.2       |\n",
      "| n_updates               | 642200    |\n",
      "| qf1_loss                | 200.96442 |\n",
      "| qf2_loss                | 197.63928 |\n",
      "| time_elapsed            | 62577     |\n",
      "| total timesteps         | 642327    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.1      |\n",
      "| episodes                | 195000    |\n",
      "| eplenmean               | 3.61      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.1      |\n",
      "| n_updates               | 652400    |\n",
      "| qf1_loss                | 175.59987 |\n",
      "| qf2_loss                | 182.87868 |\n",
      "| time_elapsed            | 63924     |\n",
      "| total timesteps         | 652576    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 21.1      |\n",
      "| episodes                | 200000    |\n",
      "| eplenmean               | 3.67      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 21.1      |\n",
      "| n_updates               | 670100    |\n",
      "| qf1_loss                | 146.93127 |\n",
      "| qf2_loss                | 138.5943  |\n",
      "| time_elapsed            | 65595     |\n",
      "| total timesteps         | 670224    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 18.8      |\n",
      "| episodes                | 205000    |\n",
      "| eplenmean               | 4.03      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 18.8      |\n",
      "| n_updates               | 688200    |\n",
      "| qf1_loss                | 225.42682 |\n",
      "| qf2_loss                | 227.36726 |\n",
      "| time_elapsed            | 67279     |\n",
      "| total timesteps         | 688326    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 28.4     |\n",
      "| episodes                | 210000   |\n",
      "| eplenmean               | 3.6      |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 28.4     |\n",
      "| n_updates               | 706900   |\n",
      "| qf1_loss                | 308.2234 |\n",
      "| qf2_loss                | 302.809  |\n",
      "| time_elapsed            | 68995    |\n",
      "| total timesteps         | 707007   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 25.4      |\n",
      "| episodes                | 215000    |\n",
      "| eplenmean               | 3.91      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 25.4      |\n",
      "| n_updates               | 725100    |\n",
      "| qf1_loss                | 330.22736 |\n",
      "| qf2_loss                | 332.38257 |\n",
      "| time_elapsed            | 70685     |\n",
      "| total timesteps         | 725266    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 26        |\n",
      "| episodes                | 220000    |\n",
      "| eplenmean               | 3.57      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 26        |\n",
      "| n_updates               | 742500    |\n",
      "| qf1_loss                | 329.55527 |\n",
      "| qf2_loss                | 330.2859  |\n",
      "| time_elapsed            | 72335     |\n",
      "| total timesteps         | 742662    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 10.8      |\n",
      "| episodes                | 225000    |\n",
      "| eplenmean               | 2.88      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 10.8      |\n",
      "| n_updates               | 760000    |\n",
      "| qf1_loss                | 342.3386  |\n",
      "| qf2_loss                | 331.44128 |\n",
      "| time_elapsed            | 74015     |\n",
      "| total timesteps         | 760129    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 19.7      |\n",
      "| episodes                | 230000    |\n",
      "| eplenmean               | 3.66      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 19.7      |\n",
      "| n_updates               | 777500    |\n",
      "| qf1_loss                | 325.58557 |\n",
      "| qf2_loss                | 320.00742 |\n",
      "| time_elapsed            | 75670     |\n",
      "| total timesteps         | 777668    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 27.9      |\n",
      "| episodes                | 235000    |\n",
      "| eplenmean               | 3.64      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 27.9      |\n",
      "| n_updates               | 795200    |\n",
      "| qf1_loss                | 333.07144 |\n",
      "| qf2_loss                | 328.80603 |\n",
      "| time_elapsed            | 77348     |\n",
      "| total timesteps         | 795352    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 24        |\n",
      "| episodes                | 240000    |\n",
      "| eplenmean               | 3.39      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 24        |\n",
      "| n_updates               | 813200    |\n",
      "| qf1_loss                | 332.81113 |\n",
      "| qf2_loss                | 335.03687 |\n",
      "| time_elapsed            | 79030     |\n",
      "| total timesteps         | 813387    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.7      |\n",
      "| episodes                | 245000    |\n",
      "| eplenmean               | 3.59      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.7      |\n",
      "| n_updates               | 831000    |\n",
      "| qf1_loss                | 328.16736 |\n",
      "| qf2_loss                | 326.88727 |\n",
      "| time_elapsed            | 80709     |\n",
      "| total timesteps         | 831120    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 21.8      |\n",
      "| episodes                | 250000    |\n",
      "| eplenmean               | 3.59      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 21.8      |\n",
      "| n_updates               | 848300    |\n",
      "| qf1_loss                | 328.9997  |\n",
      "| qf2_loss                | 316.44168 |\n",
      "| time_elapsed            | 82359     |\n",
      "| total timesteps         | 848478    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 23.2     |\n",
      "| episodes                | 255000   |\n",
      "| eplenmean               | 3.51     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 23.2     |\n",
      "| n_updates               | 865900   |\n",
      "| qf1_loss                | 331.2128 |\n",
      "| qf2_loss                | 332.4622 |\n",
      "| time_elapsed            | 84038    |\n",
      "| total timesteps         | 866078   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 12       |\n",
      "| episodes                | 260000   |\n",
      "| eplenmean               | 3.41     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 12       |\n",
      "| n_updates               | 883600   |\n",
      "| qf1_loss                | 333.4817 |\n",
      "| qf2_loss                | 333.1923 |\n",
      "| time_elapsed            | 85698    |\n",
      "| total timesteps         | 883779   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 21.8      |\n",
      "| episodes                | 265000    |\n",
      "| eplenmean               | 3.38      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 21.8      |\n",
      "| n_updates               | 901000    |\n",
      "| qf1_loss                | 336.65472 |\n",
      "| qf2_loss                | 337.6975  |\n",
      "| time_elapsed            | 87371     |\n",
      "| total timesteps         | 901151    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 22        |\n",
      "| episodes                | 270000    |\n",
      "| eplenmean               | 3.51      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 22        |\n",
      "| n_updates               | 918500    |\n",
      "| qf1_loss                | 327.21683 |\n",
      "| qf2_loss                | 322.98212 |\n",
      "| time_elapsed            | 89027     |\n",
      "| total timesteps         | 918646    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 29.1      |\n",
      "| episodes                | 275000    |\n",
      "| eplenmean               | 3.8       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 29.1      |\n",
      "| n_updates               | 935900    |\n",
      "| qf1_loss                | 334.90796 |\n",
      "| qf2_loss                | 332.5591  |\n",
      "| time_elapsed            | 90515     |\n",
      "| total timesteps         | 936077    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 21.9      |\n",
      "| episodes                | 280000    |\n",
      "| eplenmean               | 3.41      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 21.9      |\n",
      "| n_updates               | 954100    |\n",
      "| qf1_loss                | 355.90704 |\n",
      "| qf2_loss                | 357.726   |\n",
      "| time_elapsed            | 91972     |\n",
      "| total timesteps         | 954213    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 23.3      |\n",
      "| episodes                | 285000    |\n",
      "| eplenmean               | 3.62      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 23.3      |\n",
      "| n_updates               | 971500    |\n",
      "| qf1_loss                | 351.1483  |\n",
      "| qf2_loss                | 349.56433 |\n",
      "| time_elapsed            | 93407     |\n",
      "| total timesteps         | 971693    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 17.5      |\n",
      "| episodes                | 290000    |\n",
      "| eplenmean               | 3.6       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 17.5      |\n",
      "| n_updates               | 989000    |\n",
      "| qf1_loss                | 343.69495 |\n",
      "| qf2_loss                | 345.93616 |\n",
      "| time_elapsed            | 94871     |\n",
      "| total timesteps         | 989127    |\n",
      "---------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.td3.td3.TD3 at 0x206d6b289c8>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=int(1e6), log_interval=5000, callback=[checkpoint_callback,eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(checkpoint_path+\"end_manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
