{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:\n",
      "The TensorFlow contrib module will not be included in TensorFlow 2.0.\n",
      "For more information, please see:\n",
      "  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md\n",
      "  * https://github.com/tensorflow/addons\n",
      "  * https://github.com/tensorflow/io (for I/O related ops)\n",
      "If you depend on functionality not listed there, please file an issue.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "\n",
    "from stable_baselines import TD3\n",
    "from stable_baselines.td3.policies import LnMlpPolicy\n",
    "from stable_baselines.common.vec_env import DummyVecEnv\n",
    "from stable_baselines.ddpg.noise import NormalActionNoise, OrnsteinUhlenbeckActionNoise\n",
    "\n",
    "from stable_baselines.common.callbacks import CheckpointCallback, EvalCallback\n",
    "from stable_baselines.bench import Monitor\n",
    "\n",
    "from modules import CustomTD3Policy\n",
    "\n",
    "import tensorflow as tf\n",
    "tf.compat.v1.logging.set_verbosity(tf.compat.v1.logging.ERROR)\n",
    "\n",
    "from modules import KukaBulletGymRandomBall\n",
    "\n",
    "import os\n",
    "\n",
    "# Reloading any code written in external .py files.\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the logging and saving directories\n",
    "parent = \"./TD3_kuka_random_ball_deep/\"\n",
    "checkpoint_path = parent + \"checkpoints/\"\n",
    "best_model_path = parent + \"best_model/\"\n",
    "eval_log_path = parent + \"eval_logs/\"\n",
    "monitor_log_path = parent + \"monitor_logs/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make environment with monitor wrapper\n",
    "env = KukaBulletGymRandomBall.KukaBulletGym(render=False)\n",
    "wrapped_env = Monitor(env, monitor_log_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make callbacks\n",
    "checkpoint_callback = CheckpointCallback(save_freq=50000, \n",
    "                                         save_path=checkpoint_path,\n",
    "                                         name_prefix=\"model\")\n",
    "eval_callback = EvalCallback(env,\n",
    "                             best_model_save_path=best_model_path, \n",
    "                             log_path=eval_log_path,\n",
    "                             eval_freq=1000, \n",
    "                             deterministic=True, \n",
    "                             render=False,\n",
    "                             verbose=0,\n",
    "                             n_eval_episodes=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The noise objects for TD3\n",
    "n_actions = env.action_space.shape[-1]\n",
    "action_noise = NormalActionNoise(mean=np.zeros(n_actions), sigma=0.1 * np.ones(n_actions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a model without an environment, this model cannot be trained until it has a valid environment.\n"
     ]
    }
   ],
   "source": [
    "model = TD3.load(\"./TD3_kuka_fixed_ball_deep/best_model/best_model\")\n",
    "model.set_env(wrapped_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\envs\\stable_bl\\lib\\site-packages\\stable_baselines\\common\\callbacks.py:277: UserWarning: Training and eval env are not of the same type<Monitor<KukaBulletGym instance>> != <stable_baselines.common.vec_env.dummy_vec_env.DummyVecEnv object at 0x00000250EF4AC248>\n",
      "  \"{} != {}\".format(self.training_env, self.eval_env))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.269     |\n",
      "| episodes                | 5000      |\n",
      "| eplenmean               | 3         |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 0.3       |\n",
      "| n_updates               | 22400     |\n",
      "| qf1_loss                | 2.6296155 |\n",
      "| qf2_loss                | 2.7659833 |\n",
      "| time_elapsed            | 1953      |\n",
      "| total timesteps         | 22522     |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.18      |\n",
      "| episodes                | 10000     |\n",
      "| eplenmean               | 4.76      |\n",
      "| fps                     | 11        |\n",
      "| mean 100 episode reward | 0.2       |\n",
      "| n_updates               | 41900     |\n",
      "| qf1_loss                | 1.5520765 |\n",
      "| qf2_loss                | 1.6096742 |\n",
      "| time_elapsed            | 3725      |\n",
      "| total timesteps         | 42004     |\n",
      "---------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ep_rewmean              | 0.72        |\n",
      "| episodes                | 15000       |\n",
      "| eplenmean               | 3.23        |\n",
      "| fps                     | 10          |\n",
      "| mean 100 episode reward | 0.7         |\n",
      "| n_updates               | 58600       |\n",
      "| qf1_loss                | 0.03183244  |\n",
      "| qf2_loss                | 0.031382054 |\n",
      "| time_elapsed            | 5349        |\n",
      "| total timesteps         | 58736       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ep_rewmean              | 0.76        |\n",
      "| episodes                | 20000       |\n",
      "| eplenmean               | 3.11        |\n",
      "| fps                     | 10          |\n",
      "| mean 100 episode reward | 0.8         |\n",
      "| n_updates               | 74300       |\n",
      "| qf1_loss                | 0.024949174 |\n",
      "| qf2_loss                | 0.025559533 |\n",
      "| time_elapsed            | 7004        |\n",
      "| total timesteps         | 74446       |\n",
      "-----------------------------------------\n",
      "-----------------------------------------\n",
      "| current_lr              | 0.0003      |\n",
      "| ep_rewmean              | 1.12        |\n",
      "| episodes                | 25000       |\n",
      "| eplenmean               | 3.4         |\n",
      "| fps                     | 10          |\n",
      "| mean 100 episode reward | 1.1         |\n",
      "| n_updates               | 90300       |\n",
      "| qf1_loss                | 0.032129634 |\n",
      "| qf2_loss                | 0.031248843 |\n",
      "| time_elapsed            | 8725        |\n",
      "| total timesteps         | 90463       |\n",
      "-----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.801     |\n",
      "| episodes                | 30000     |\n",
      "| eplenmean               | 3.76      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.8       |\n",
      "| n_updates               | 109000    |\n",
      "| qf1_loss                | 2.6631489 |\n",
      "| qf2_loss                | 2.6671805 |\n",
      "| time_elapsed            | 10597     |\n",
      "| total timesteps         | 109179    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.856     |\n",
      "| episodes                | 35000     |\n",
      "| eplenmean               | 3.86      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.9       |\n",
      "| n_updates               | 127900    |\n",
      "| qf1_loss                | 2.7745156 |\n",
      "| qf2_loss                | 2.7605042 |\n",
      "| time_elapsed            | 12473     |\n",
      "| total timesteps         | 128005    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.688     |\n",
      "| episodes                | 40000     |\n",
      "| eplenmean               | 3.85      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| n_updates               | 147300    |\n",
      "| qf1_loss                | 2.8360944 |\n",
      "| qf2_loss                | 2.8511693 |\n",
      "| time_elapsed            | 14450     |\n",
      "| total timesteps         | 147492    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.824     |\n",
      "| episodes                | 45000     |\n",
      "| eplenmean               | 3.76      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.8       |\n",
      "| n_updates               | 166400    |\n",
      "| qf1_loss                | 3.7040775 |\n",
      "| qf2_loss                | 3.6979477 |\n",
      "| time_elapsed            | 16512     |\n",
      "| total timesteps         | 166506    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 1.85     |\n",
      "| episodes                | 50000    |\n",
      "| eplenmean               | 3.55     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 1.9      |\n",
      "| n_updates               | 183800   |\n",
      "| qf1_loss                | 3.987002 |\n",
      "| qf2_loss                | 3.89573  |\n",
      "| time_elapsed            | 18314    |\n",
      "| total timesteps         | 183970   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.793     |\n",
      "| episodes                | 55000     |\n",
      "| eplenmean               | 3.58      |\n",
      "| fps                     | 9         |\n",
      "| mean 100 episode reward | 0.8       |\n",
      "| n_updates               | 200900    |\n",
      "| qf1_loss                | 4.691929  |\n",
      "| qf2_loss                | 4.7263536 |\n",
      "| time_elapsed            | 20109     |\n",
      "| total timesteps         | 201081    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 1.83     |\n",
      "| episodes                | 60000    |\n",
      "| eplenmean               | 3.5      |\n",
      "| fps                     | 9        |\n",
      "| mean 100 episode reward | 1.8      |\n",
      "| n_updates               | 218700   |\n",
      "| qf1_loss                | 9.545187 |\n",
      "| qf2_loss                | 9.676124 |\n",
      "| time_elapsed            | 21909    |\n",
      "| total timesteps         | 218824   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.651     |\n",
      "| episodes                | 65000     |\n",
      "| eplenmean               | 3.76      |\n",
      "| fps                     | 9         |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| n_updates               | 237000    |\n",
      "| qf1_loss                | 3.874893  |\n",
      "| qf2_loss                | 3.8960388 |\n",
      "| time_elapsed            | 23767     |\n",
      "| total timesteps         | 237173    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 1.86      |\n",
      "| episodes                | 70000     |\n",
      "| eplenmean               | 3.78      |\n",
      "| fps                     | 9         |\n",
      "| mean 100 episode reward | 1.9       |\n",
      "| n_updates               | 255400    |\n",
      "| qf1_loss                | 6.6423955 |\n",
      "| qf2_loss                | 6.6592083 |\n",
      "| time_elapsed            | 25608     |\n",
      "| total timesteps         | 255527    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 0.746    |\n",
      "| episodes                | 75000    |\n",
      "| eplenmean               | 3.77     |\n",
      "| fps                     | 9        |\n",
      "| mean 100 episode reward | 0.7      |\n",
      "| n_updates               | 273600   |\n",
      "| qf1_loss                | 5.524427 |\n",
      "| qf2_loss                | 5.562868 |\n",
      "| time_elapsed            | 27441    |\n",
      "| total timesteps         | 273717   |\n",
      "--------------------------------------\n",
      "----------------------------------------\n",
      "| current_lr              | 0.0003     |\n",
      "| ep_rewmean              | 0.715      |\n",
      "| episodes                | 80000      |\n",
      "| eplenmean               | 3.84       |\n",
      "| fps                     | 9          |\n",
      "| mean 100 episode reward | 0.7        |\n",
      "| n_updates               | 291300     |\n",
      "| qf1_loss                | 0.99819916 |\n",
      "| qf2_loss                | 0.97744524 |\n",
      "| time_elapsed            | 29266      |\n",
      "| total timesteps         | 291467     |\n",
      "----------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.924     |\n",
      "| episodes                | 85000     |\n",
      "| eplenmean               | 3.5       |\n",
      "| fps                     | 9         |\n",
      "| mean 100 episode reward | 0.9       |\n",
      "| n_updates               | 308700    |\n",
      "| qf1_loss                | 2.7582405 |\n",
      "| qf2_loss                | 2.81348   |\n",
      "| time_elapsed            | 31066     |\n",
      "| total timesteps         | 308872    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 3.11     |\n",
      "| episodes                | 90000    |\n",
      "| eplenmean               | 3.23     |\n",
      "| fps                     | 9        |\n",
      "| mean 100 episode reward | 3.1      |\n",
      "| n_updates               | 326700   |\n",
      "| qf1_loss                | 9.306212 |\n",
      "| qf2_loss                | 9.401782 |\n",
      "| time_elapsed            | 32889    |\n",
      "| total timesteps         | 326830   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 0.579    |\n",
      "| episodes                | 95000    |\n",
      "| eplenmean               | 3.73     |\n",
      "| fps                     | 9        |\n",
      "| mean 100 episode reward | 0.6      |\n",
      "| n_updates               | 348400   |\n",
      "| qf1_loss                | 26.21669 |\n",
      "| qf2_loss                | 22.63855 |\n",
      "| time_elapsed            | 34896    |\n",
      "| total timesteps         | 348502   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 1.7       |\n",
      "| episodes                | 100000    |\n",
      "| eplenmean               | 4.13      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 1.7       |\n",
      "| n_updates               | 368500    |\n",
      "| qf1_loss                | 31.49083  |\n",
      "| qf2_loss                | 29.772095 |\n",
      "| time_elapsed            | 36810     |\n",
      "| total timesteps         | 368650    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 1.85      |\n",
      "| episodes                | 105000    |\n",
      "| eplenmean               | 4.81      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 1.9       |\n",
      "| n_updates               | 390500    |\n",
      "| qf1_loss                | 34.51706  |\n",
      "| qf2_loss                | 34.510536 |\n",
      "| time_elapsed            | 38810     |\n",
      "| total timesteps         | 390639    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.703     |\n",
      "| episodes                | 110000    |\n",
      "| eplenmean               | 5.36      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| n_updates               | 416200    |\n",
      "| qf1_loss                | 31.733902 |\n",
      "| qf2_loss                | 29.80406  |\n",
      "| time_elapsed            | 41013     |\n",
      "| total timesteps         | 416342    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 1.65      |\n",
      "| episodes                | 115000    |\n",
      "| eplenmean               | 4.91      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 1.7       |\n",
      "| n_updates               | 444700    |\n",
      "| qf1_loss                | 26.4413   |\n",
      "| qf2_loss                | 23.426325 |\n",
      "| time_elapsed            | 43369     |\n",
      "| total timesteps         | 444812    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.98      |\n",
      "| episodes                | 120000    |\n",
      "| eplenmean               | 4.27      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 3         |\n",
      "| n_updates               | 466700    |\n",
      "| qf1_loss                | 25.380661 |\n",
      "| qf2_loss                | 24.656506 |\n",
      "| time_elapsed            | 45386     |\n",
      "| total timesteps         | 466849    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 4.03     |\n",
      "| episodes                | 125000   |\n",
      "| eplenmean               | 4.4      |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 4        |\n",
      "| n_updates               | 488900   |\n",
      "| qf1_loss                | 39.47546 |\n",
      "| qf2_loss                | 40.24255 |\n",
      "| time_elapsed            | 47441    |\n",
      "| total timesteps         | 489071   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.72      |\n",
      "| episodes                | 130000    |\n",
      "| eplenmean               | 5.85      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.7       |\n",
      "| n_updates               | 507000    |\n",
      "| qf1_loss                | 41.99173  |\n",
      "| qf2_loss                | 41.493362 |\n",
      "| time_elapsed            | 49238     |\n",
      "| total timesteps         | 507119    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 4.05      |\n",
      "| episodes                | 135000    |\n",
      "| eplenmean               | 5.34      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 4.1       |\n",
      "| n_updates               | 532100    |\n",
      "| qf1_loss                | 28.173435 |\n",
      "| qf2_loss                | 28.05848  |\n",
      "| time_elapsed            | 51373     |\n",
      "| total timesteps         | 532285    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 3.97      |\n",
      "| episodes                | 140000    |\n",
      "| eplenmean               | 5.6       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 4         |\n",
      "| n_updates               | 558600    |\n",
      "| qf1_loss                | 28.640326 |\n",
      "| qf2_loss                | 29.310598 |\n",
      "| time_elapsed            | 53681     |\n",
      "| total timesteps         | 558798    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 4.13      |\n",
      "| episodes                | 145000    |\n",
      "| eplenmean               | 4.6       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 4.1       |\n",
      "| n_updates               | 585600    |\n",
      "| qf1_loss                | 33.755726 |\n",
      "| qf2_loss                | 23.454924 |\n",
      "| time_elapsed            | 56005     |\n",
      "| total timesteps         | 585707    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.733     |\n",
      "| episodes                | 150000    |\n",
      "| eplenmean               | 4.39      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.7       |\n",
      "| n_updates               | 608000    |\n",
      "| qf1_loss                | 28.752626 |\n",
      "| qf2_loss                | 28.83291  |\n",
      "| time_elapsed            | 58061     |\n",
      "| total timesteps         | 608166    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.16      |\n",
      "| episodes                | 155000    |\n",
      "| eplenmean               | 4.39      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.2       |\n",
      "| n_updates               | 630100    |\n",
      "| qf1_loss                | 41.67976  |\n",
      "| qf2_loss                | 44.066593 |\n",
      "| time_elapsed            | 60090     |\n",
      "| total timesteps         | 630276    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2         |\n",
      "| episodes                | 160000    |\n",
      "| eplenmean               | 4.59      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2         |\n",
      "| n_updates               | 652400    |\n",
      "| qf1_loss                | 21.772455 |\n",
      "| qf2_loss                | 21.569075 |\n",
      "| time_elapsed            | 62148     |\n",
      "| total timesteps         | 652525    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 1.62      |\n",
      "| episodes                | 165000    |\n",
      "| eplenmean               | 5.03      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 1.6       |\n",
      "| n_updates               | 676200    |\n",
      "| qf1_loss                | 31.567322 |\n",
      "| qf2_loss                | 34.522835 |\n",
      "| time_elapsed            | 64266     |\n",
      "| total timesteps         | 676320    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.599     |\n",
      "| episodes                | 170000    |\n",
      "| eplenmean               | 3.56      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.6       |\n",
      "| n_updates               | 698700    |\n",
      "| qf1_loss                | 30.395737 |\n",
      "| qf2_loss                | 29.568792 |\n",
      "| time_elapsed            | 66266     |\n",
      "| total timesteps         | 698816    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 2.76     |\n",
      "| episodes                | 175000   |\n",
      "| eplenmean               | 4.55     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 2.8      |\n",
      "| n_updates               | 717300   |\n",
      "| qf1_loss                | 50.04926 |\n",
      "| qf2_loss                | 48.45981 |\n",
      "| time_elapsed            | 68115    |\n",
      "| total timesteps         | 717481   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 7.41      |\n",
      "| episodes                | 180000    |\n",
      "| eplenmean               | 4.6       |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 7.4       |\n",
      "| n_updates               | 740100    |\n",
      "| qf1_loss                | 57.713642 |\n",
      "| qf2_loss                | 51.46545  |\n",
      "| time_elapsed            | 70198     |\n",
      "| total timesteps         | 740213    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.06      |\n",
      "| episodes                | 185000    |\n",
      "| eplenmean               | 4.59      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.1       |\n",
      "| n_updates               | 763500    |\n",
      "| qf1_loss                | 76.731995 |\n",
      "| qf2_loss                | 78.17727  |\n",
      "| time_elapsed            | 72302     |\n",
      "| total timesteps         | 763637    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.88      |\n",
      "| episodes                | 190000    |\n",
      "| eplenmean               | 4.23      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.9       |\n",
      "| n_updates               | 785900    |\n",
      "| qf1_loss                | 58.26686  |\n",
      "| qf2_loss                | 59.180965 |\n",
      "| time_elapsed            | 74354     |\n",
      "| total timesteps         | 786041    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.474     |\n",
      "| episodes                | 195000    |\n",
      "| eplenmean               | 4.22      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 0.5       |\n",
      "| n_updates               | 806900    |\n",
      "| qf1_loss                | 50.053165 |\n",
      "| qf2_loss                | 51.911713 |\n",
      "| time_elapsed            | 76305     |\n",
      "| total timesteps         | 807096    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 0.896    |\n",
      "| episodes                | 200000   |\n",
      "| eplenmean               | 4.23     |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 0.9      |\n",
      "| n_updates               | 828000   |\n",
      "| qf1_loss                | 23.0227  |\n",
      "| qf2_loss                | 17.25404 |\n",
      "| time_elapsed            | 78261    |\n",
      "| total timesteps         | 828161   |\n",
      "--------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.02      |\n",
      "| episodes                | 205000    |\n",
      "| eplenmean               | 3.26      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2         |\n",
      "| n_updates               | 848000    |\n",
      "| qf1_loss                | 23.50407  |\n",
      "| qf2_loss                | 14.900106 |\n",
      "| time_elapsed            | 80371     |\n",
      "| total timesteps         | 848140    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 3.82      |\n",
      "| episodes                | 210000    |\n",
      "| eplenmean               | 2.72      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 3.8       |\n",
      "| n_updates               | 862900    |\n",
      "| qf1_loss                | 22.162378 |\n",
      "| qf2_loss                | 22.115877 |\n",
      "| time_elapsed            | 82130     |\n",
      "| total timesteps         | 863036    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 0.967     |\n",
      "| episodes                | 215000    |\n",
      "| eplenmean               | 4.16      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 1         |\n",
      "| n_updates               | 878700    |\n",
      "| qf1_loss                | 43.462814 |\n",
      "| qf2_loss                | 43.001907 |\n",
      "| time_elapsed            | 83810     |\n",
      "| total timesteps         | 878896    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.2       |\n",
      "| episodes                | 220000    |\n",
      "| eplenmean               | 4.21      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2.2       |\n",
      "| n_updates               | 899400    |\n",
      "| qf1_loss                | 24.454693 |\n",
      "| qf2_loss                | 25.434673 |\n",
      "| time_elapsed            | 85764     |\n",
      "| total timesteps         | 899531    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 2.02      |\n",
      "| episodes                | 225000    |\n",
      "| eplenmean               | 4.06      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 2         |\n",
      "| n_updates               | 919900    |\n",
      "| qf1_loss                | 34.815094 |\n",
      "| qf2_loss                | 30.314404 |\n",
      "| time_elapsed            | 87717     |\n",
      "| total timesteps         | 920012    |\n",
      "---------------------------------------\n",
      "---------------------------------------\n",
      "| current_lr              | 0.0003    |\n",
      "| ep_rewmean              | 6.15      |\n",
      "| episodes                | 230000    |\n",
      "| eplenmean               | 4.04      |\n",
      "| fps                     | 10        |\n",
      "| mean 100 episode reward | 6.2       |\n",
      "| n_updates               | 940300    |\n",
      "| qf1_loss                | 55.218395 |\n",
      "| qf2_loss                | 63.03215  |\n",
      "| time_elapsed            | 89648     |\n",
      "| total timesteps         | 940483    |\n",
      "---------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 5.73     |\n",
      "| episodes                | 235000   |\n",
      "| eplenmean               | 4.2      |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 5.7      |\n",
      "| n_updates               | 960700   |\n",
      "| qf1_loss                | 65.78314 |\n",
      "| qf2_loss                | 70.94727 |\n",
      "| time_elapsed            | 91570    |\n",
      "| total timesteps         | 960870   |\n",
      "--------------------------------------\n",
      "--------------------------------------\n",
      "| current_lr              | 0.0003   |\n",
      "| ep_rewmean              | 7.43     |\n",
      "| episodes                | 240000   |\n",
      "| eplenmean               | 4.2      |\n",
      "| fps                     | 10       |\n",
      "| mean 100 episode reward | 7.4      |\n",
      "| n_updates               | 981500   |\n",
      "| qf1_loss                | 78.12485 |\n",
      "| qf2_loss                | 68.7061  |\n",
      "| time_elapsed            | 93535    |\n",
      "| total timesteps         | 981687   |\n",
      "--------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<stable_baselines.td3.td3.TD3 at 0x250fb72ea88>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.learn(total_timesteps=int(1e6), log_interval=5000, callback=[checkpoint_callback,eval_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(checkpoint_path+\"end_manual\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
